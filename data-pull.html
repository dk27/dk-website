<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta http-equiv="X-UA-Compatible" content="ie=edge">
    <title>Data Pulling</title>
    <link href="https://fonts.googleapis.com/css?family=Indie+Flower|Lora&display=swap" rel="stylesheet">
    <link rel="stylesheet" href="styles/styles.css">
    <script src="http://ajax.googleapis.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
</head>

<body>
    <header>
        <nav>
            <ul class="firstUL">
                <li><a href="index.html">home</a></li>
                <li><a href="#" class="about">about</a></li>
                <li><a href="#" target=_blank>archive</a></li>
                <li><a href="#" target=_blank>contact</a></li>
            </ul>
        </nav>
        <div class="wrapper">
            <h1>Don't you love data?</h1>
            <h2>Data Science Blog</h2>
        </div>
    </header>
    <main>
        <div class="wrapper">
            <section>
                <div class="data-pulling-section">
                    <h2 class="page-title">Intoduction to Importing Data in Python</h2>
                    <p>As a data scientist, you really need to get comfortable with working with data. Before you can
                        build
                        a cool machine learning model, you need to spend significant amount of time on figuring out
                        where the data resides and in
                        which format, how to access it, join multiple tables together and prepare it for further
                        analysis.
                        In this post, I will cover most data formats I had a chance to work with and how to load them in
                        Python</p>
                    <h3>CSV Files</h3>
                    <p>CSV files are propably the least common data format that I personally get to work with, but I've
                        interviewed quite a few people who primarily work with csv files, so it's important to cover
                        them</p>
                    <p>I downloaded a GDP csv file from the <a
                            href="https://datacatalog.worldbank.org/dataset/gdp-ranking" target="_blank"
                            class="link">World Bank</a>. Fortunately, the downloaded file is quite messy. There are
                        extra empty columns, empty top and bottom (about 100) rows, columns with information that we may
                        not want, and column names take up two cells. While you can clean the file up in Excel, let's
                        have some fun and clean it in Python.
                    </p>

                    <div class="csv-pull">
                        <img src="styles/csv_pull.PNG" alt="screenshot of CSV file">
                    </div>
                    <p>
                        In this example, we will use <i>read_csv</i> function from Pandas library which comes with a
                        variety of helpful options. One of Panda's disadvantages is the library is big, and I've ran
                        into a few problems with referencing it during deployment stages, but we are simply trying to
                        load a csv file into Python, so I opted to use it. There is a csv module in Python that is also
                        worth looking into.
                    </p>
                    <p>How do we clean the file up? We can use <i>skiprows</i> option to remove empty top rows. We can
                        also drop the 3rd and 6th columns since they aren't needed. We will also rename columns in the
                        data frame. Lastly, we will use <i>dropna</i> function to remove rows with at least one missing
                        value. </p>
                    <script src="https://gist.github.com/dk27/bb2bc8dce817fdd59ebe80ed1fd74a94.js"></script>
                    <h3>Relational Databases</h3>
                    <p>Most of the data I work with resides in relational databases, such as MySQL, Microsoft SQL
                        Server or Oracle.
                        I'll cover a few Python libraries that I've used in the past. There are a few things these libraries have in common. The first thing is a connection needs to be established by specifying server name, database name, password and username. Typical next step would be creating a cursor object to run queries against the database</p>
                    <h4>Pypyodbc</h4>
                    Note: This library might give you problems if you deploy an application in Serverless environment.
                    <h4>PyMySQL</h4>
                    <h4>Oracle</h4>
                    <h4>Pony</h4>
                    <h3>JSON data</h3>
                    <p>This is another data format that I frequently work with. Most of the JSON data in my case comes
                        from
                        a variety of APIs, so I think it's important to cover how to access and work with JSON data in
                        Python</p>
                    <h3>XML data</h3>
                    <p>This is my least favorite data format to work with. It also typically comes from APIs either REST
                        or
                        SOAP. Unlike JSON data which is easily parsed in python as shown above as long as you understand
                        the
                        structure of the file, XML requires extra manipulating. That said, there are a few libraries in
                        Python that can make this task a little easier for you</p>

                </div>

            </section>
        </div>
    </main>
</body>

</html>